{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "For this assignment you need to:\n",
    "    Prepare the data - stopwords, stemming\n",
    "    Apply both: bag of words and tfIdf\n",
    "    Apply Logistic Regression, SVM, and NaiveBayes for the ready dataset\n",
    "    Compare accuracies for bag of words and tfidf with all the algorithms above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The sentiment labels are:\n",
    "\n",
    "0 - negative\n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0  7072]\n",
      " [    1 27273]\n",
      " [    2 79582]\n",
      " [    3 32927]\n",
      " [    4  9206]]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_table('data.tsv')\n",
    "A = data['Sentiment']\n",
    "B = np.bincount(A)\n",
    "ii = np.nonzero(B)[0]\n",
    "a = np.array([ii,B[ii]])\n",
    "print(a.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "def filter_punc_stopwrds(txt):\n",
    "    txtin=BeautifulSoup(txt,'lxml').get_text()\n",
    "    nopunc=''.join( c for c in stemmer.stem(txtin.lower())  ) \n",
    "    return ' '.join( word for word in nopunc.split() if word not in stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "data['New'] = data['Phrase'].apply(filter_punc_stopwrds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         series escapades demonstrating adage good goos...\n",
       "1            series escapades demonstrating adage good goos\n",
       "2                                                      seri\n",
       "3                                                          \n",
       "4                                                      seri\n",
       "5                   escapades demonstrating adage good goos\n",
       "6                                                          \n",
       "7                   escapades demonstrating adage good goos\n",
       "8                                                   escapad\n",
       "9                             demonstrating adage good goos\n",
       "10                                       demonstrating adag\n",
       "11                                                 demonstr\n",
       "12                                                     adag\n",
       "13                                                         \n",
       "14                                                     adag\n",
       "15                                                good goos\n",
       "16                                                         \n",
       "17                                                good goos\n",
       "18                                                         \n",
       "19                                                good goos\n",
       "20                                                         \n",
       "21                                                good goos\n",
       "22                                                     good\n",
       "23                                                     goos\n",
       "24                                                         \n",
       "25                                                     goos\n",
       "26                                                     goos\n",
       "27        also good gander , occasionally amuses none am...\n",
       "28        also good gander , occasionally amuses none am...\n",
       "29                                                     also\n",
       "                                ...                        \n",
       "156030                                       joke united st\n",
       "156031      movie 's downfall substitute plot personality .\n",
       "156032                                     movie 's downfal\n",
       "156033                        substitute plot personality .\n",
       "156034                               substitute plot person\n",
       "156035                               substitute plot person\n",
       "156036                               substitute plot person\n",
       "156037                                      substitute plot\n",
       "156038                                               person\n",
       "156039    film darkly atmospheric , herrmann quietly sug...\n",
       "156040    darkly atmospheric , herrmann quietly suggesti...\n",
       "156041    darkly atmospheric , herrmann quietly suggesti...\n",
       "156042                                 darkly atmospheric ,\n",
       "156043                                     darkly atmospher\n",
       "156044    herrmann quietly suggesting sadness obsession ...\n",
       "156045    herrmann quietly suggesting sadness obsession ...\n",
       "156046                                             herrmann\n",
       "156047    quietly suggesting sadness obsession beneath h...\n",
       "156048    suggesting sadness obsession beneath hearst 's...\n",
       "156049                            suggesting sadness obsess\n",
       "156050                                       sadness obsess\n",
       "156051                                       sadness obsess\n",
       "156052                                              sadness\n",
       "156053            beneath hearst 's forced avuncular chortl\n",
       "156054                    hearst 's forced avuncular chortl\n",
       "156055                                               hearst\n",
       "156056                              forced avuncular chortl\n",
       "156057                                     avuncular chortl\n",
       "156058                                            avuncular\n",
       "156059                                               chortl\n",
       "Name: New, Length: 156060, dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['New']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1],\n",
       "       [1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "corpus = np.array(data['New'][:5])\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21404559, 0.26530399, 0.26530399, 0.26530399, 0.21404559,\n",
       "        0.21404559, 0.26530399, 0.42809118, 0.        , 0.26530399,\n",
       "        0.26530399, 0.26530399, 0.26530399, 0.        , 0.21404559,\n",
       "        0.26530399],\n",
       "       [0.39114171, 0.        , 0.        , 0.        , 0.39114171,\n",
       "        0.39114171, 0.        , 0.39114171, 0.48481007, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.39114171,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfvectorizer = TfidfVectorizer()\n",
    "corpus = np.array(data['New'][:5])\n",
    "Y = tfvectorizer.fit_transform(corpus)\n",
    "Y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. SVM:  90.26 %\n",
      "2. NaiveBayes Multinomial: 80.90 %\n",
      "3. Logistic Regression:  76.78 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "x_train = data.loc[:12000, 'New'].values\n",
    "y_train = data.loc[:12000, 'Sentiment'].values\n",
    "x_test = data.loc[:266, 'New'].values\n",
    "y_test = data.loc[:266, 'Sentiment'].values\n",
    "\n",
    "\n",
    "classifier1 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB(alpha=0.00000001))])\n",
    "\n",
    "classifier2 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression( solver='saga',multi_class='multinomial'))])\n",
    "\n",
    "classifier3 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC(gamma=10,kernel='poly'))])\n",
    "\n",
    "classifier1.fit(x_train, y_train)\n",
    "predicted = classifier1.predict(x_test)\n",
    "\n",
    "classifier2.fit(x_train, y_train)\n",
    "predicted2 = classifier2.predict(x_test)\n",
    "\n",
    "classifier3.fit(x_train, y_train)\n",
    "predicted3 = classifier3.predict(x_test)\n",
    "# get the accuracy\n",
    "print (\"1. SVM: \", \"%.2f\" % (accuracy_score(y_test, predicted3)*100), \"%\")\n",
    "print (\"2. NaiveBayes Multinomial:\", \"%.2f\" % (accuracy_score(y_test, predicted)*100), \"%\")\n",
    "print (\"3. Logistic Regression: \", \"%.2f\" % (accuracy_score(y_test, predicted2)*100), \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
